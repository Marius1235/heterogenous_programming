{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ebc65f96",
   "metadata": {},
   "source": [
    "<center> <h1> Heterogeneous Computing for AI </h1> </center>\n",
    "\n",
    "<center> <h2> Lecture 02 -: Hands-on Exercise</h2> </center>\n",
    "\n",
    "<center> <h4> Raghava Mukkamala (rrm.digi@cbs.dk)</h4> </center>\n",
    "\n",
    "Instructions\n",
    "\n",
    "Please use Python 3 for working on the following questions.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a6dddc",
   "metadata": {},
   "source": [
    "## Exercise 01:  Simple Python Program "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111d7887",
   "metadata": {},
   "source": [
    "### Write a simple python script that reads the data from 'numbers.txt' file and sums them up.\n",
    "\n",
    "Please note that numbers.txt file is available in the same folder."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6063a86f",
   "metadata": {},
   "source": [
    "### Your Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fc7a0610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9946\n"
     ]
    }
   ],
   "source": [
    "# The following function reads the numbers and add them all.\n",
    "def read_file(path: str) -> int:\n",
    "    \n",
    "    with open(path) as f:\n",
    "        \n",
    "        lines = f.readlines()\n",
    "\n",
    "    sum = 0\n",
    "\n",
    "    for line in lines:\n",
    "\n",
    "        sum += int(line.strip())\n",
    "\n",
    "    return sum\n",
    "\n",
    "print(read_file('numbers.txt'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd781c81",
   "metadata": {},
   "source": [
    "## Exercise 02:  Analyse the follwing Scenerio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5869eb",
   "metadata": {},
   "source": [
    "#### If you had to read 100 files in your local storage like 'numbers.txt'. Would you opt to use threads to speed up the reading? Why/why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9feccdc7",
   "metadata": {},
   "source": [
    "### Discuss your answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92cb61c8",
   "metadata": {},
   "source": [
    "The performance gains from using mulitple threads to read from a local file directory\n",
    "might be minimal. The reason being that accessing data stored in a local filesystem incurs/takes a lot less time\n",
    "than downlading data from the internet. Therefore the I/O costs of reading local files might not be high enough \n",
    "to justify the effort needed to multi-thread your program.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee902cbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d019b205",
   "metadata": {},
   "source": [
    "## Exercise 03:  Multi-thread Downloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb9fef9",
   "metadata": {},
   "source": [
    "Let's take a look at an I/O intensive operation as follows:-\n",
    "\n",
    "Please look at the downloads.py file provided for these exercises.\n",
    "Using the concurrent.futures library, create a multi-threaded version of the web page downlaods.\n",
    "Report the speedup provided by the multi-threaded version."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b260ae",
   "metadata": {},
   "source": [
    "### Your Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11f0cc2",
   "metadata": {},
   "source": [
    "#### Version 1: A simple version with fixed number of threds (5 threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8f16c536",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For URL:  https://twitter.com 125049\n",
      "For URL:  https://twitter.com 125062\n",
      "For URL:  https://www.linkedin.com 117854\n",
      "For URL:  https://facebook.com 71178\n",
      "For URL:  https://facebook.com 71177\n",
      "For URL:  https://www.linkedin.com 117861\n",
      "For URL:  https://www.linkedin.com 117861\n",
      "For URL:  https://twitter.com 125047\n",
      "For URL:  https://twitter.com 125085\n",
      "For URL:  https://facebook.com 71177\n",
      "For URL:  https://www.linkedin.com 117861\n",
      "For URL:  https://www.linkedin.com 117861\n",
      "For URL:  https://twitter.com 125318\n",
      "For URL:  https://facebook.com 71181\n",
      "For URL:  https://facebook.com 71178\n",
      "For URL:  https://www.linkedin.com 117861\n",
      "For URL:  https://twitter.com 125051\n",
      "For URL:  https://twitter.com 125038\n",
      "For URL:  https://facebook.com 71178\n",
      "For URL:  https://facebook.com 71178\n",
      "For URL:  https://www.linkedin.com 117861\n",
      "For URL:  https://twitter.com 125068\n",
      "For URL:  https://www.linkedin.com 117861\n",
      "For URL:  https://twitter.com 125038\n",
      "For URL:  https://facebook.com 71181\n",
      "For URL:  https://www.linkedin.com 117861\n",
      "For URL:  https://www.linkedin.com 117861\n",
      "For URL:  https://twitter.com 125069\n",
      "For URL:  https://facebook.com 71178\n",
      "For URL:  https://facebook.com 71177\n",
      "Time taken:  18.193190097808838 Seconds\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import time\n",
    "from threading import Thread\n",
    "\n",
    "\n",
    "def download_site(url):\n",
    "    with requests.get(url) as response:\n",
    "        # lets print the results out here \n",
    "        print(\"For URL: \", url, len(response.content))\n",
    "        return len(response.content)\n",
    "\n",
    "\n",
    "def download_all_sites(urls):\n",
    "    # We are going to create 5 threads and reuse them to go through the list of 30 links.\n",
    "\n",
    "    # Since we have 5 threads, we are going to iterate through 5 links at a time and give\n",
    "    # each link to one of the 5 threads\n",
    "\n",
    "    for i in range(0,len(urls),5):\n",
    "\n",
    "        # Initialise the threads\n",
    "        t1 = Thread(target=download_site, args=(urls[i],))\n",
    "        t2 = Thread(target=download_site, args=(urls[i+1],))\n",
    "        t3 = Thread(target=download_site, args=(urls[i+2],))\n",
    "        t4 = Thread(target=download_site, args=(urls[i+3],))\n",
    "        t5 = Thread(target=download_site, args=(urls[i+4],))\n",
    "\n",
    "        # Start all the threads\n",
    "        t1.start()\n",
    "        t2.start()\n",
    "        t3.start()\n",
    "        t4.start()\n",
    "        t5.start()\n",
    "\n",
    "\n",
    "        # Wait for all the threads to finish\n",
    "        t1.join()\n",
    "        t2.join()\n",
    "        t3.join()\n",
    "        t4.join()\n",
    "        t5.join()\n",
    "        \n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    start_time = time.time()\n",
    "\n",
    "    links = [\"https://twitter.com\",\"https://facebook.com\", \"https://www.linkedin.com\"] * 10\n",
    "    download_all_sites(links)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    print(\"Time taken: \", end_time - start_time, \"Seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5567103f",
   "metadata": {},
   "source": [
    "#### Version 2: Solution with configurable number of threads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "abef78aa",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For URL: For URL: For URL:  https://www.linkedin.com 117861\n",
      " https://www.linkedin.com https://www.linkedin.com 117861\n",
      " 117861\n",
      "For URL:  https://www.linkedin.com 117861\n",
      "For URL: For URL: For URL: For URL:  https://twitter.com 125079\n",
      " https://www.linkedin.com 117861\n",
      "For URL:  https://www.linkedin.com 117861\n",
      " https://www.linkedin.com 117861\n",
      " https://twitter.com 125047\n",
      "For URL:  https://www.linkedin.com 117861\n",
      "For URL:  https://www.linkedin.com 117861\n",
      "For URL:  https://www.linkedin.com 117861\n",
      "For URL:  https://twitter.com 125330\n",
      "For URL:  https://twitter.com 125047\n",
      "For URL: For URL:  https://twitter.com 125036\n",
      " https://twitter.com 125049\n",
      "For URL: For URL:  https://facebook.com 71181\n",
      " https://facebook.com 71179\n",
      "For URL:  https://facebook.com 71178\n",
      "For URL: For URL:  https://facebook.com 71178\n",
      " https://facebook.com 71179\n",
      "For URL:  https://facebook.com 71177\n",
      "For URL:  https://facebook.com 71176\n",
      "For URL: For URL:  https://twitter.com 125049 https://twitter.com 125038\n",
      "\n",
      "For URL:  https://twitter.com 125328\n",
      "For URL:  https://twitter.com 125053\n",
      "For URL:  https://facebook.com 71176\n",
      "For URL:  https://facebook.com 71173\n",
      "For URL:  https://facebook.com 71176\n",
      "Time taken:  2.6827690601348877 Seconds\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import time\n",
    "from threading import Thread\n",
    "\n",
    "# Global variables\n",
    "no_of_threads = 30\n",
    "\n",
    "def download_site(url):\n",
    "    with requests.get(url) as response:\n",
    "        # lets print the results out here \n",
    "        print(\"For URL: \", url, len(response.content))\n",
    "        return len(response.content)\n",
    "\n",
    "def download_all_sites(urls):\n",
    "    # We are going to create n (no_of_threads) threads and reuse them to go through the list of 30 links.\n",
    "\n",
    "    # Since we have n (no_of_threads) threads, we are going to iterate through the urls list till we complete \n",
    "    # all the URLs.   \n",
    "    # Here the stategy is to create n (no_of_threads) threads and let them complete their job and then \n",
    "    # go with the next batch of n (no_of_threads) threads, untill we complete all the urls.\n",
    "\n",
    "    \n",
    "    url_index = 0\n",
    "    \n",
    "    while url_index < len(urls):\n",
    "        \n",
    "        thread_pool = []\n",
    "        \n",
    "        for i in range(no_of_threads):\n",
    "\n",
    "            t1 = Thread(target=download_site, args=(urls[url_index],))\n",
    "            \n",
    "            thread_pool.append(t1)\n",
    "\n",
    "            t1.start()\n",
    "\n",
    "            url_index = url_index + 1\n",
    "\n",
    "            if url_index == len(urls):\n",
    "                break\n",
    "\n",
    "        # join all the threads.\n",
    "        for thread in thread_pool:\n",
    "            thread.join()\n",
    "            \n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    start_time = time.time()\n",
    "\n",
    "    links = [\"https://twitter.com\",\"https://facebook.com\", \"https://www.linkedin.com\"] * 10\n",
    "    download_all_sites(links)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    print(\"Time taken: \", end_time - start_time, \"Seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56be96ed",
   "metadata": {},
   "source": [
    "#### Version 3: Solution with ThreadPoolExecutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9d00df18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For URL:  https://twitter.com 125323\n",
      "For URL:  https://facebook.com 71180\n",
      "For URL:  https://www.linkedin.com 117854\n",
      "For URL:  https://twitter.com 125319\n",
      "For URL:  https://facebook.com 71176\n",
      "For URL:  https://www.linkedin.com 117861\n",
      "For URL:  https://twitter.com 125070\n",
      "For URL:  https://facebook.com 71177\n",
      "For URL:  https://www.linkedin.com 117854\n",
      "For URL:  https://twitter.com 125047\n",
      "For URL:  https://facebook.com 71190\n",
      "For URL:  https://www.linkedin.com 117861\n",
      "For URL:  https://twitter.com 125036\n",
      "For URL:  https://facebook.com 71172\n",
      "For URL:  https://www.linkedin.com 117861\n",
      "For URL:  https://twitter.com 125038\n",
      "For URL:  https://facebook.com 71176\n",
      "For URL:  https://www.linkedin.com 117861\n",
      "For URL:  https://twitter.com 125066\n",
      "For URL:  https://facebook.com 71177\n",
      "For URL:  https://www.linkedin.com 117861\n",
      "For URL:  https://twitter.com 125276\n",
      "For URL:  https://facebook.com 71176\n",
      "For URL:  https://www.linkedin.com 117861\n",
      "For URL:  https://twitter.com 125047\n",
      "For URL:  https://facebook.com 71177\n",
      "For URL:  https://www.linkedin.com 117861\n",
      "For URL:  https://twitter.com 125038\n",
      "For URL:  https://facebook.com 71177\n",
      "For URL:  https://www.linkedin.com 117861\n",
      "Time taken:  3.156486988067627 Seconds\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "The following python script downloads data from a set of webpages.\n",
    "This is a classic example of downloading webpages and the standard for introducing concurrency.\n",
    "'''\n",
    "\n",
    "import requests\n",
    "import time\n",
    "import concurrent.futures\n",
    "\n",
    "def download_site(url):\n",
    "    with requests.get(url) as response:\n",
    "        return url, len(response.content)\n",
    "\n",
    "def download_all_sites(urls):\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        results = executor.map(download_site, urls)\n",
    "\n",
    "    for url, result in results:\n",
    "        print(\"For URL: \", url, result)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    start_time = time.time()\n",
    "\n",
    "    links = [\"https://twitter.com\",\"https://facebook.com\", \"https://www.linkedin.com\"] * 10\n",
    "    download_all_sites(links)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    print(\"Time taken: \", end_time - start_time, \"Seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb6fe1de",
   "metadata": {},
   "source": [
    "## Exercise 04:  Multi-thread Range Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b86f2f4",
   "metadata": {},
   "source": [
    "This exercise is related to the file range_counter.py (found in the same folder) \n",
    "\n",
    "Using the concurrent.futures library, create a multi-threaded version of applying the range_counter function.\n",
    "\n",
    "That is, apply the range_counter function to the data by utilising threads. \n",
    "\n",
    "Comment on the performance of the multi-threaded version."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb380e5",
   "metadata": {},
   "source": [
    "### Your Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "15ed5d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from typing import List\n",
    "import numpy as np \n",
    "from threading import Thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a56071ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global variables\n",
    "no_of_threads = 10\n",
    "# we'll use a dictionary to keep track of all the values returned by the range_counter function\n",
    "dict_results = {}\n",
    "\n",
    "# for sequential version\n",
    "dict_results_seq = {}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "29d41a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def range_counter(row: List[int], index, dict_results, min: int = 5, max: int = 10) -> int:\n",
    "    '''\n",
    "    Returns the number of values in the row that fall between the given range\n",
    "        Args:\n",
    "            i.   row : Lst of numbers\n",
    "            ii.  min : minimum value of range\n",
    "            iii. max : maximum values of range\n",
    "\n",
    "        Returns: a count (int) of values that fall in the range\n",
    "    '''\n",
    "    count = 0\n",
    "    for val in row:\n",
    "        if min <= val <= max:\n",
    "            count += 1\n",
    "    # Save value in dictionary \n",
    "    dict_results[index] = count\n",
    "    return count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f53067cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_range_counter_sequential(data: List[List[int]]) -> List[int]:\n",
    "    '''\n",
    "    This function takes data and applies the range_counter function\n",
    "    over all the rows in the data\n",
    "    '''\n",
    "    index = 0\n",
    "    for row in data:\n",
    "        temp_result = range_counter(row, index, dict_results_seq)\n",
    "        index += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9ce56de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_range_counter_multithreaded(data: List[List[int]]) -> List[int]:\n",
    "    row_index = 0\n",
    "\n",
    "    while row_index < len(data):\n",
    "        thread_pool = []\n",
    "\n",
    "        for i in range(no_of_threads):\n",
    "            t1 = Thread(target=range_counter, args=(data[row_index], row_index,dict_results))\n",
    "\n",
    "            thread_pool.append(t1)\n",
    "\n",
    "            t1.start()\n",
    "\n",
    "            row_index += 1\n",
    "\n",
    "            if row_index == len(data):\n",
    "                break\n",
    "        \n",
    "        # wait for all threads to complete by joining on all the threads\n",
    "\n",
    "        for thread in thread_pool:\n",
    "            thread.join()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1bd9d8c",
   "metadata": {},
   "source": [
    "#### Test code to run the program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "01554e19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished sequential execution in 0.16 seconds\n",
      "First 5 values are:  4 8 5 2 4\n",
      "finished concurrent execution in 10.27 seconds\n",
      "First 5 values are:  4 8 5 2 4\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    # Providing a seed ensures we can get the same 'random' values\n",
    "    #  generated each time (Good for testing)\n",
    "    np.random.seed(0)\n",
    "\n",
    "    # create a matrix with dimensions 200x5 (200 rows and 5 columns)\n",
    "    arr = np.random.randint(0, 10, size=[200000, 10])\n",
    "\n",
    "    # Convert into lists of lists\n",
    "    data = arr.tolist()\n",
    "\n",
    "    start = time.perf_counter()\n",
    "\n",
    "    apply_range_counter_sequential(data)\n",
    "\n",
    "\n",
    "    finish = time.perf_counter()\n",
    "    print(f'finished sequential execution in {round(finish-start, 2)} seconds')\n",
    "    print(\"First 5 values are: \",dict_results_seq[0],dict_results_seq[1],dict_results_seq[2],dict_results_seq[3],dict_results_seq[4])\n",
    "\n",
    "    start = time.perf_counter()\n",
    "\n",
    "    apply_range_counter_multithreaded(data)\n",
    "\n",
    "\n",
    "    finish = time.perf_counter()\n",
    "    print(f'finished concurrent execution in {round(finish-start, 2)} seconds')\n",
    "    print(\"First 5 values are: \",dict_results[0],dict_results[1],dict_results[2],dict_results[3],dict_results[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7669d452",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34fddfb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4d09c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f930bde",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3160567",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11e3998",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
