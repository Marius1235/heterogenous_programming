{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "afa7906f",
   "metadata": {},
   "source": [
    "<center> <h1> Heterogeneous Computing for AI </h1> </center>\n",
    "\n",
    "<center> <h2> Lecture 02 -: Hands-on Exercise</h2> </center>\n",
    "\n",
    "<center> <h4> Raghava Mukkamala (rrm.digi@cbs.dk)</h4> </center>\n",
    "\n",
    "Instructions\n",
    "\n",
    "Please use Python 3 for working on the following questions.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2edbd80c",
   "metadata": {},
   "source": [
    "## Exercise 01:  Simple Python Program "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e7a0c6b",
   "metadata": {},
   "source": [
    "### Write a simple python script that reads the data from 'numbers.txt' file and sums them up.\n",
    "\n",
    "Please note that numbers.txt file is available in the same folder."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05684582",
   "metadata": {},
   "source": [
    "### Your Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc55cbfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 178.,  567.,   23.,  178., 9000.])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "numbers = np.loadtxt(\"numbers.txt\")\n",
    "\n",
    "numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a5c0a2",
   "metadata": {},
   "source": [
    "## Exercise 02:  Analyse the follwing Scenerio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109209b6",
   "metadata": {},
   "source": [
    "#### If you had to read 100 files in your local storage like 'numbers.txt'. Would you opt to use threads to speed up the reading? Why/why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2710159c",
   "metadata": {},
   "source": [
    "### Discuss your answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628b7af1",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c105b175",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nAs you need to wait for I/O operations when reading the 100 files, threading will help in increasing the speed to the reading.\\nThe reading it self will be the bottelneck and doing multiple reading will speed up the process.\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "As you need to wait for I/O operations when reading the 100 files, threading will help in increasing the speed to the reading.\n",
    "The reading it self will be the bottelneck and doing multiple reading will speed up the process.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e47001",
   "metadata": {},
   "source": [
    "## Exercise 03:  Multi-thread Downloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32772bc4",
   "metadata": {},
   "source": [
    "Let's take a look at an I/O intensive operation as follows:-\n",
    "\n",
    "Please look at the downloads.py file provided for these exercises.\n",
    "Using the concurrent.futures library, create a multi-threaded version of the web page downlaods.\n",
    "Report the speedup provided by the multi-threaded version."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb6cd030",
   "metadata": {},
   "source": [
    "### Your Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e57536c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://twitter.com\n",
      "https://facebook.com\n",
      "https://linkedin.com\n"
     ]
    }
   ],
   "source": [
    "links = [\"https://twitter.com\", \"https://facebook.com\", \"https://linkedin.com\"]\n",
    "\n",
    "for link in links:\n",
    "    print(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "431f200a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting the 1th with Urls= https://twitter.com, https://facebook.com and https://linkedin.com\n",
      "Starting the 2th with Urls= https://twitter.com, https://facebook.com and https://linkedin.com\n",
      "Starting the 3th with Urls= https://twitter.com, https://facebook.com and https://linkedin.com\n",
      "Starting the 4th with Urls= https://twitter.com, https://facebook.com and https://linkedin.com\n",
      "Starting the 5th with Urls= https://twitter.com, https://facebook.com and https://linkedin.com\n",
      "Starting the 6th with Urls= https://twitter.com, https://facebook.com and https://linkedin.com\n",
      "Starting the 7th with Urls= https://twitter.com, https://facebook.com and https://linkedin.com\n",
      "Starting the 8th with Urls= https://twitter.com, https://facebook.com and https://linkedin.com\n",
      "Starting the 9th with Urls= https://twitter.com, https://facebook.com and https://linkedin.com\n",
      "Starting the 10th with Urls= https://twitter.com, https://facebook.com and https://linkedin.com\n",
      "For URL:  https://twitter.com 125432\n",
      "For URL:  https://twitter.com 125443\n",
      "For URL:  https://twitter.com 125449\n",
      "For URL:  https://twitter.com For URL:  https://twitter.com 125464\n",
      "125434\n",
      "For URL:  https://twitter.com 125443\n",
      "For URL:  https://twitter.com 125481\n",
      "For URL:  https://twitter.com 125468\n",
      "For URL:  https://twitter.com 125432\n",
      "For URL:  https://twitter.com 125475\n",
      "For URL:  https://facebook.com 64244\n",
      "For URL:  https://facebook.com 64244\n",
      "For URL:  https://facebook.com 64254\n",
      "For URL:  https://facebook.com 64243\n",
      "For URL:  https://facebook.com 64248\n",
      "For URL:  https://facebook.com 64248\n",
      "For URL:  https://facebook.com 64249\n",
      "For URL:  https://facebook.com 64251\n",
      "For URL:  https://facebook.com 64247\n",
      "For URL:  https://facebook.com 64246\n",
      "For URL:  https://linkedin.com 142098\n",
      "For URL:  https://linkedin.com 120493\n",
      "For URL:  https://linkedin.com 120493\n",
      "For URL:  https://linkedin.com 120493\n",
      "closing <Thread(Thread-5, stopped 12660)>\n",
      "closing <Thread(Thread-6, stopped 21640)>\n",
      "For URL:  https://linkedin.com 120493\n",
      "For URL:  https://linkedin.com 120493\n",
      "closing <Thread(Thread-7, stopped 18816)>\n",
      "For URL:  https://linkedin.com 120493\n",
      "For URL:  https://linkedin.com 120493\n",
      "For URL:  https://linkedin.com 120493\n",
      "closing <Thread(Thread-8, stopped 13864)>\n",
      "For URL:  https://linkedin.com 120493\n",
      "closing <Thread(Thread-9, stopped 9568)>\n",
      "closing <Thread(Thread-10, stopped 20488)>\n",
      "closing <Thread(Thread-11, stopped 15916)>\n",
      "closing <Thread(Thread-12, stopped 19016)>\n",
      "closing <Thread(Thread-13, stopped 12240)>\n",
      "closing <Thread(Thread-14, stopped 16204)>\n",
      "It took  2.33 second(s) to complete!\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import time\n",
    "from threading import Thread\n",
    "\n",
    "def download_site(url):\n",
    "    with requests.get(url) as response:\n",
    "        return len(response.content)\n",
    "    \n",
    "def download_all_sites(urls):\n",
    "    for url in urls:\n",
    "        print(\"For URL: \", url, download_site(url))\n",
    "\n",
    "start_time = time.perf_counter()\n",
    "\n",
    "#create and start 10 threads\n",
    "threads = []\n",
    "links = [\"https://twitter.com\", \"https://facebook.com\", \"https://linkedin.com\"]\n",
    "\n",
    "for n in range(1, 11):\n",
    "    \n",
    "    t = Thread(target=download_all_sites, args=(links,))\n",
    "\n",
    "    threads.append(t)\n",
    "\n",
    "    print(f\"Starting the {n}th with Urls= {links[0]}, {links[1]} and {links[2]}\")\n",
    "    t.start()\n",
    "        \n",
    "# Waiting for the threads to complete\n",
    "for t in threads:\n",
    "    \n",
    "    t.join()\n",
    "    print(f\"closing {t}\")\n",
    "    \n",
    "end_time = time.perf_counter()\n",
    "\n",
    "print(f\"It took {end_time - start_time: 0.2f} second(s) to complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ea2a86",
   "metadata": {},
   "source": [
    "<p>Creating 10 seperate threads improved the speed of execution from roughly 16sec to 2-3sec</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "871f28f3",
   "metadata": {},
   "source": [
    "## Exercise 04:  Multi-thread Range Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b24712",
   "metadata": {},
   "source": [
    "This exercise is related to the file range_counter.py (found in the same folder) \n",
    "\n",
    "Using the concurrent.futures library, create a multi-threaded version of applying the range_counter function.\n",
    "\n",
    "That is, apply the range_counter function to the data by utilising threads. \n",
    "\n",
    "Comment on the performance of the multi-threaded version."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4529fb6",
   "metadata": {},
   "source": [
    "### Your Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45f3f662",
   "metadata": {},
   "outputs": [],
   "source": [
    "from threading import Thread\n",
    "import time\n",
    "from typing import List\n",
    "import numpy as np\n",
    "from concurrent.futures import ProcessPoolExecutor \n",
    "import concurrent.futures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5516ebe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def range_counter(row: List[int], min: int = 5, max: int = 10) -> int:\n",
    "    \"\"\"\n",
    "    Returns the number of values in the row that fall between the given range\n",
    "        Args:\n",
    "        i.   row: List of numbers\n",
    "        ii.  min: minimum values of range\n",
    "        iii. max: maximum values of range\n",
    "        \n",
    "        Returns: a count(int) of values that fall in the range\n",
    "    \"\"\"\n",
    "    count = 0\n",
    "    for val in row:\n",
    "        if min <= val <= max:\n",
    "            count += 1\n",
    "        return count\n",
    "    \n",
    "def apply_range_counter_concurrently(lists, min=5, max = 10):\n",
    "    \n",
    "    processes = []\n",
    "    result = []\n",
    "        \n",
    "    with ProcessPoolExecutor() as executor:\n",
    "        for n in lists:\n",
    "            process = executor.submit(range_counter, n, min, max)\n",
    "            \n",
    "            processes.append(process)\n",
    "        \n",
    "        for p in processes:\n",
    "            result.append(p.result())\n",
    "    \n",
    "    \n",
    "    return result\n",
    "    \"\"\"\n",
    "    def apply_range_counter_concurrently(data: List[List[int]],\n",
    "                                     min: int,\n",
    "                                     max: int) -> List[int]:\n",
    "    \"\"\"\n",
    "    #This function takes data and applies the range_counter function \n",
    "    #over all the rows in the data\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    with future.ProcessPoolExecutor() as executor:\n",
    "        \n",
    "        futures = {executor.submit(apply_range_counter_concurrently, \n",
    "                                         data, 5, 10): row in data}\n",
    "        \n",
    "        for fut in future.as_completed(futures):\n",
    "            \n",
    "            count = future_to_row[fut]\n",
    "            \n",
    "            try: \n",
    "                result.append(row.result())\n",
    "            except Exception as exc:\n",
    "                print(\"%r generated an exception: %s\" % (count, exc))\n",
    "            \n",
    "    return result\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4e6d0158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5, 0, 3, 3, 7], [9, 3, 5, 2, 4], [7, 6, 8, 8, 1], [6, 7, 7, 8, 1], [5, 9, 8, 9, 4], [3, 0, 3, 5, 0], [2, 3, 8, 1, 3], [3, 3, 7, 0, 1], [9, 9, 0, 4, 7], [3, 2, 7, 2, 0]]\n"
     ]
    },
    {
     "ename": "BrokenProcessPool",
     "evalue": "A child process terminated abruptly, the process pool is not usable anymore",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mBrokenProcessPool\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [11]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m#timing the concurrent solution\u001b[39;00m\n\u001b[0;32m     14\u001b[0m start_concurrent \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mperf_counter()\n\u001b[1;32m---> 16\u001b[0m conc_result \u001b[38;5;241m=\u001b[39m \u001b[43mapply_range_counter_concurrently\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m end_concurrent \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mperf_counter()\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFinished concurrent computation in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mend_concurrent\u001b[38;5;241m-\u001b[39mstart_concurrent\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m second(s)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Input \u001b[1;32mIn [10]\u001b[0m, in \u001b[0;36mapply_range_counter_concurrently\u001b[1;34m(lists, min, max)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ProcessPoolExecutor() \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m n \u001b[38;5;129;01min\u001b[39;00m lists:\n\u001b[1;32m---> 24\u001b[0m         process \u001b[38;5;241m=\u001b[39m \u001b[43mexecutor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubmit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrange_counter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mmin\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mmax\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m         processes\u001b[38;5;241m.\u001b[39mappend(process)\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m processes:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\concurrent\\futures\\process.py:681\u001b[0m, in \u001b[0;36mProcessPoolExecutor.submit\u001b[1;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    679\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown_lock:\n\u001b[0;32m    680\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_broken:\n\u001b[1;32m--> 681\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m BrokenProcessPool(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_broken)\n\u001b[0;32m    682\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown_thread:\n\u001b[0;32m    683\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcannot schedule new futures after shutdown\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mBrokenProcessPool\u001b[0m: A child process terminated abruptly, the process pool is not usable anymore"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    #Provide a seed to get the same \"random\" values each time\n",
    "    np.random.seed(0)\n",
    "    \n",
    "    #create a matrix with dimensions 200x5 (200rows and 5 columns)\n",
    "    arr = np.random.randint(0, 10, size=[200, 5])\n",
    "    \n",
    "    #convert into a List of lists\n",
    "    data = arr.tolist()\n",
    "    \n",
    "    print(data[0:10])\n",
    "    \n",
    "    #timing the concurrent solution\n",
    "    start_concurrent = time.perf_counter()\n",
    "    \n",
    "    conc_result = apply_range_counter_concurrently(data, 5, 10)\n",
    "    \n",
    "    end_concurrent = time.perf_counter()\n",
    "    \n",
    "    print(f\"Finished concurrent computation in {end_concurrent-start_concurrent} second(s)\")\n",
    "    print(f\"First 10 results of the concurrent result: {conc_result[:10]}\")\n",
    "    \n",
    "print(\"done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1bb0cc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32fe7773",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9081d8d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
